{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  5 04:03:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 43%   51C    P0    68W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 43%   51C    P0    59W / 280W |      0MiB / 24220MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 39%   48C    P0    59W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 29%   55C    P0    54W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "1024\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/0/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/1/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/2/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/3/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/4/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/5/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/6/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/7/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/8/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/9/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/10/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/11/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/12/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/13/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/14/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/15/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/16/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/17/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/18/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/19/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/20/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/21/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/22/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/23/weight.pth\n",
      "/workspace/flat_feet/Unet/weight_unet1024_noSCSE/24/weight.pth\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import copy\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from visualize_single_image import*\n",
    "\n",
    "\n",
    "######### !!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################\n",
    "sys.path.append('/workspace/flat_feet/Unet/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_manet/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet384/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet512/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet768/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet1024/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet384_finetune/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet512_finetune/\" # path_root of Unet weight\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet1024_finetune/\" # path_root of Unet weight\n",
    "HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_unet1024_noSCSE/\" # path_root of Unet weight\n",
    "######### !!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################\n",
    "\n",
    "from trainer import *\n",
    "from loss import *\n",
    "from Unet import *\n",
    "from preprocessing import *\n",
    "from datagenerater import *\n",
    "from utils import *\n",
    "from progressbar import Bar\n",
    "from PIL import Image\n",
    "# import SimpleITK as sitk\n",
    "\n",
    "# HISTORY_PATH = \"/mnt/nas125/InHwanKim/weight/rsm/segmentation(all)/\"\n",
    "# DIR = '/mnt/nas125/InHwanKim/data/rsm/'\n",
    "# class_path = DIR + '/classes.csv'\n",
    "# HISTORY_PATH = \"/workspace/flat_feet/Unet/weight_origin/\"\n",
    "\n",
    "\n",
    "#테스트_데이터 로드\n",
    "image_paths = []\n",
    "gt_paths = []\n",
    "\n",
    "max_size = 4000\n",
    "if '384' in HISTORY_PATH:\n",
    "    shift = patch_size = 384\n",
    "elif '512' in HISTORY_PATH:\n",
    "    shift = patch_size = 512\n",
    "elif '1024' in HISTORY_PATH:\n",
    "    shift = patch_size = 1024\n",
    "else:\n",
    "    shift = patch_size = 512\n",
    "print(patch_size)\n",
    "\n",
    "weight_paths = []\n",
    "for i in range(25):\n",
    "    path = HISTORY_PATH + str(i) + \"/\"\n",
    "    model_name = os.listdir(path)[-1]\n",
    "    modle_path = path + model_name\n",
    "    weight_paths.append(modle_path)\n",
    "    \n",
    "for i in range(len(weight_paths)):\n",
    "    print(weight_paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference Retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install natsort --user\n",
    "# test Retinanet 1 stage\n",
    "import glob\n",
    "from tqdm import trange\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "######### !!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################\n",
    "DIR = '/workspace/flat_feet/dataset/png_test/'\n",
    "# DIR = '/workspace/flat_feet/dataset/Segmentation_210712/ExternalValidation/LERA_WBLR/refined/'\n",
    "# DIR = '/workspace/flat_feet/dataset/Segmentation_210712/ExternalValidation/AMC_100_WBLR/refined/'\n",
    "\n",
    "# ###########################for ROI tuning (from validset)###############################\n",
    "# label_paths = natsorted(glob.glob(DIR+'label/*.npy'))[800:1023]\n",
    "# # label_paths = natsorted(glob.glob(DIR+'label/*.npy'))[800:1023]\n",
    "# image_paths = list()\n",
    "# for idx in range(len(label_paths)):\n",
    "#     image_paths.append(glob.glob(DIR+'image/'+label_paths[idx].split('/')[-1][:-4])[0])\n",
    "# ########################################################################################\n",
    "\n",
    "image_paths = natsorted(glob.glob(DIR + '*png'))\n",
    "label_paths = natsorted(glob.glob(\"/workspace/flat_feet/dataset/flat_feet/label_test/*.npy\"))\n",
    "# image_paths = natsorted(glob.glob(DIR + 'image_test_2nd/*png'))\n",
    "# label_paths = natsorted(glob.glob(DIR + \"label_test_2nd/*npy\"))\n",
    "# image_paths = image_paths[:len(label_paths)]\n",
    "print(len(image_paths),len(label_paths))\n",
    "######### !!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################\n",
    "\n",
    "model_path = \"/workspace/flat_feet/pytorch-retinanet/weight/retinanet_120.pt\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "GT_Points = []\n",
    "Predict_Points = []\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(len(image_paths))):\n",
    "    patient_distance = []\n",
    "    Predict_Point = []\n",
    "    \n",
    "    Predict_Info = detect_image(model, image_paths[i])\n",
    "    image_orig = cv2.imread(image_paths[i])\n",
    "    \n",
    "#     for j in range(Predict_Info.shape[0]-1):\n",
    "    for j in range(25):\n",
    "        P_X_point = int(((Predict_Info[j][1])+int(Predict_Info[j][3]))/2)\n",
    "        P_Y_point = int(((Predict_Info[j][2])+int(Predict_Info[j][4]))/2)\n",
    "        pr_point = [P_X_point,P_Y_point]\n",
    "        Predict_Point.append(pr_point)\n",
    "    \n",
    "    Predict_Points.append(Predict_Point)\n",
    "    try:\n",
    "        label = np.load(label_paths[i])\n",
    "        GT_Points.append(label)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#     # plots\n",
    "#     fig, ax = plt.subplots(figsize=(16,10))\n",
    "#     ax.imshow(image_orig)\n",
    "#     j = 0\n",
    "#     for j in range(25):\n",
    "#         rect = patches.Rectangle((Predict_Info[j][1], Predict_Info[j][2]), Predict_Info[j][3]-Predict_Info[j][1], Predict_Info[j][4]-Predict_Info[j][2], linewidth=1, edgecolor='r', facecolor='none',alpha=1)\n",
    "#         ax.add_patch(rect)\n",
    "\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "print(np.array(Predict_Points).shape,np.array(GT_Points).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Info[j][3]-Predict_Info[j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Info[j][4]-Predict_Info[j][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Info[j][1], Predict_Info[j][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(image_orig)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "Predict_Info\n",
    "j = 0\n",
    "for j in range(25):\n",
    "    rect = patches.Rectangle((Predict_Info[j][1], Predict_Info[j][2]), Predict_Info[j][3]-Predict_Info[j][1], Predict_Info[j][4]-Predict_Info[j][2], linewidth=1, edgecolor='r', facecolor='none',alpha=1)\n",
    "    # rect = patches.Rectangle((Predict_Info[j][1], Predict_Info[j][2]), 1024, 1024, linewidth=1, edgecolor='r', facecolor='none',alpha=1)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view (you can skip)\n",
    "# for i in range(len(image_paths)):\n",
    "#     print(image_paths[i].split(\"/\")[-1])\n",
    "#     img = cv2.imread(image_paths[i])\n",
    "#     for j in range(25):\n",
    "#         cv2.circle(img,((Predict_Points[i][j][0]),(Predict_Points[i][j][1])),8,(255,0,0),-1 )\n",
    "# #         cv2.circle(img,((GT_Points[i][j][0]),(GT_Points[i][j][1])),8,(0,0,255),-1 )\n",
    "        \n",
    "#     plt.figure(figsize=(14, 14))\n",
    "#     plt.title('GT:Red, Pred:Blue,')\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference Unet(25 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4010 , 1~22\n",
    "# !pip install timm==0.3.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict_Point Retina\n",
    "# ppoints Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Resize(object):\n",
    "#     def __call__(self, sample, x_size= 2048):\n",
    "#         image = sample['image']\n",
    "#         landmarks = sample['landmarks']\n",
    "#         x_ori, y_ori,_ = image.shape\n",
    "#         image = cv2.resize(image, (x_size,int((x_size*y_ori)/x_ori)))\n",
    "#         landmarks = cv2.resize(landmarks, (x_size,int((x_size*y_ori)/x_ori)))\n",
    "        \n",
    "#         image_ = np.zeros((x_size,y_size))\n",
    "#         landmarks_ = np.zeros((x_size,y_size))\n",
    "#         print(image.shape,image_.shape)\n",
    "        \n",
    "#         if image.shape[1]>=y_size:\n",
    "#             image_= image[-y_size:]\n",
    "#             landmarks_= landmarks[-y_size:]\n",
    "#         elif image.shape[1]<y_size:\n",
    "#             image_[-y_size:]= image\n",
    "#             landmarks_[-y_size:]= landmarks\n",
    "            \n",
    "#         image = np.expand_dims(image_,2)\n",
    "#         landmarks = np.expand_dims(landmarks_,2)\n",
    "        \n",
    "#         plt.imshow(image)\n",
    "#         plt.imshow(landmarks,alpha=0.3)\n",
    "#         plt.show()\n",
    "        \n",
    "#         return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "def Resize(image, x_size= 2048):\n",
    "    y_ori, x_ori = image.shape\n",
    "    image = cv2.resize(image, (x_size,int((x_size*y_ori)/x_ori)))\n",
    "    ratio = x_size/x_ori\n",
    "    return image, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch --user --quiet\n",
    "# !pip install ipywidgets --user\n",
    "#########################!!!!!!!!!!!!!!!!!!!!!!#################################\n",
    "# model = UNet(n_channels = 1, n_classes = 1)\n",
    "import segmentation_models_pytorch as smp\n",
    "# model = smp.Unet(encoder_name='timm-tf_efficientnet_lite4',decoder_attention_type='scse', in_channels = 1, classes = 1)\n",
    "model = smp.Unet(encoder_name='timm-tf_efficientnet_lite4',decoder_attention_type=None, in_channels = 1, classes = 1)\n",
    "#########################!!!!!!!!!!!!!!!!!!!!!!#################################\n",
    "\n",
    "ppoints = np.zeros((len(image_paths),25,2),dtype=np.uint32)\n",
    "\n",
    "for LM in range(0,25):\n",
    "    device = torch.device('cuda')\n",
    "    model.load_state_dict(torch.load(weight_paths[LM]))\n",
    "    model.to(device)\n",
    "\n",
    "    for j in tqdm(range(len(image_paths))):\n",
    "        temp_image = cv2.imread(image_paths[j],0)\n",
    "        temp_image, ratio = Resize(temp_image)\n",
    "        \n",
    "        padding_image = np.zeros((max_size,max_size),dtype=np.uint8)\n",
    "        padding_image[shift:temp_image.shape[0]+shift,shift:temp_image.shape[1]+shift] = temp_image \n",
    "                \n",
    "        left_up = (int((Predict_Points[j][LM][0]*ratio-(patch_size/2) + shift)),int((Predict_Points[j][LM][1]*ratio-(patch_size/2)+ shift)))\n",
    "        right_down = (int((Predict_Points[j][LM][0]*ratio+(patch_size/2)+ shift)),int((Predict_Points[j][LM][1]*ratio+(patch_size/2)+ shift)))\n",
    "\n",
    "        image = padding_image[left_up[1]:right_down[1],left_up[0]:right_down[0]]\n",
    "        if image.shape != (patch_size,patch_size):\n",
    "            image = image[:patch_size,:patch_size]\n",
    "        image = Pre_Processing(image)\n",
    "        \n",
    "        output = model(image)\n",
    "        output= torch.sigmoid(output)\n",
    "        pr_mask = output.squeeze().cpu().detach().numpy()[:,:].round()\n",
    "                \n",
    "        pr_x_mean,pr_y_mean = Get_Center_Points(pr_mask)\n",
    "        \n",
    "#         ppoints[j][LM][0] = left_up[0] + pr_x_mean - shift\n",
    "#         ppoints[j][LM][1] = left_up[1] + pr_y_mean - shift\n",
    "        ppoints[j][LM][0] = (left_up[0] + pr_x_mean - shift)/ratio \n",
    "        ppoints[j][LM][1] = (left_up[1] + pr_y_mean - shift)/ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and view (you can skip)\n",
    "# max_idx = 22\n",
    "max_idx = 25\n",
    "radius = 16\n",
    "alpha = 0.7\n",
    "\n",
    "save_path = DIR + f\"result_{max_idx}/gt_pred_patchsize{patch_size}/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for i in range(len(image_paths)):\n",
    "    print(image_paths[i])\n",
    "    img = cv2.imread(image_paths[i])\n",
    "    lm_unet = lm_retina = lm_gt = np.zeros_like(img)\n",
    "    out = img.copy()\n",
    "    for j in range(max_idx):\n",
    "        try:\n",
    "            cv2.circle(img,((ppoints[i][j][0]),(ppoints[i][j][1])),radius, (255,0,0),-1 ) # Unet\n",
    "            # cv2.circle(lm_unet,((ppoints[i][j][0]),(ppoints[i][j][1])),radius, (255,0,0),-1 ) # Unet\n",
    "            # out = cv2.addWeighted(img, alpha, lm_unet, 1 - alpha, 0)            \n",
    "            # cv2.circle(img,((Predict_Points[i][j][0]),(Predict_Points[i][j][1])),radius,(0,0,255),-1) # RetinaNet\n",
    "            cv2.circle(img,((GT_Points[i][j][0]),(GT_Points[i][j][1])),radius,(0,255,0),-1 ) # GT\n",
    "        except:\n",
    "            pass\n",
    "#             print('error_fname_i_j',image_paths[i],i,j)\n",
    "\n",
    "    for j in range(max_idx): # Unet numbering\n",
    "        try:\n",
    "            h = ppoints[i][j][1]\n",
    "            w = ppoints[i][j][0]\n",
    "            # font\n",
    "            ((text_width, text_height), _) = cv2.getTextSize(str(j), cv2.FONT_HERSHEY_SIMPLEX, 1.1, 5)    \n",
    "\n",
    "            cv2.putText(img, \n",
    "                text=str(j+1),\n",
    "                # org=(w- int(0.5 * text_width), h - int(0.5 * text_height)),\n",
    "                org=(w- int(0.7 * text_width), h - int(1.0 * text_height)),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=1.5, \n",
    "                color=(255,0,0),               \n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "#     for j in range(max_idx): # Retina numbering\n",
    "#         try:\n",
    "#             h = Predict_Points[i][j][1]\n",
    "#             w = Predict_Points[i][j][0]\n",
    "#             # font\n",
    "#             ((text_width, text_height), _) = cv2.getTextSize(str(j), cv2.FONT_HERSHEY_SIMPLEX, 1.1, 5)    \n",
    "\n",
    "#             cv2.putText(img, \n",
    "#                 text=str(j+1),\n",
    "#                 org=(w- int(0.5 * text_width), h - int(0.5 * text_height)),\n",
    "#                 fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                 fontScale=1.1, \n",
    "#                 color=(0,0,255), #B                 \n",
    "#                 thickness=2,\n",
    "#                 lineType=cv2.LINE_AA,\n",
    "#             )\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "    for j in range(max_idx): # GT numbering\n",
    "        try:\n",
    "            h = GT_Points[i][j][1]\n",
    "            w = GT_Points[i][j][0]\n",
    "            # font\n",
    "            ((text_width, text_height), _) = cv2.getTextSize(str(j), cv2.FONT_HERSHEY_SIMPLEX, 1.1, 5)    \n",
    "\n",
    "            cv2.putText(img, \n",
    "                text=str(j+1),\n",
    "                org=(w- int(0.5 * text_width), h - int(0.5 * text_height)),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=1.1, \n",
    "                color=(0,255,0), #G\n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.title('Retina : Red, U-Net : Blue, GT : Green')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    print(save_path + image_paths[i].split(\"/\")[-1], img.shape)\n",
    "    cv2.imwrite(save_path + image_paths[i].split(\"/\")[-1], cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "np.save(save_path+'Unet_xy_coordinate.npy',ppoints)\n",
    "np.save(save_path+'RetinaNet_xy_coordinate.npy',np.array(Predict_Points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ppoints.shape)\n",
    "\n",
    "# import pandas as pd\n",
    "# lst = range(0,25)\n",
    "# df = pd.DataFrame([ppoints[...,idx,0] for idx in lst])\n",
    "# df = df.T\n",
    "# df.to_csv('Unet_ROI'+str(patch_size)+'_x.csv')# please write save code \n",
    "# # df.to_csv('LERA_Retina_ROI'+str(patch_size)+'_x.csv')# please write save code \n",
    "\n",
    "# df = pd.DataFrame([ppoints[...,idx,1] for idx in lst])\n",
    "# df = df.T\n",
    "# df.to_csv('Unet_ROI'+str(patch_size)+'_y.csv')# please write save code \n",
    "# # df.to_csv('LERA_Retina_ROI'+str(patch_size)+'_y.csv')# please write save code \n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pydicom\n",
    "# files = natsorted(glob.glob('/workspace/flat_feet/dataset/Segmentation_210712/AMC_100_WBLR/original/*.dcm'))\n",
    "# spacings = list()\n",
    "# for idx in range(len(files)):\n",
    "#     dcm = pydicom.dcmread(files[idx])\n",
    "#     spacings.append(dcm.ImagerPixelSpacing)\n",
    "# spacings = np.array(spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_Points = np.array(GT_Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoints.shape,GT_Points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT_Points = np.load('../result/1024_KIM/Unet_xy_coordinate.npy')\n",
    "ppoints = np.load('../result/1024_KIM/Unet_xy_coordinate.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'UnetwoSCSEimport pandas as pd\n",
    "_ROI1024'\n",
    "lst = range(0,25)\n",
    "df = pd.DataFrame([result_delta[...,idx,0] for idx in lst])\n",
    "df = df.T\n",
    "df.to_csv(name+str(patch_size)+'_x.csv',index=False) \n",
    "\n",
    "df = pd.DataFrame([result_delta[...,idx,1] for idx in lst])\n",
    "df = df.T\n",
    "df.to_csv(name+str(patch_size)+'_y.csv',index=False)\n",
    "\n",
    "df = pd.DataFrame([result_distance[...,idx] for idx in lst])\n",
    "df = df.T\n",
    "df.to_csv(name+str(patch_size)+'_distance.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_675/4189071238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresult_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGT_Points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Unet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# result_delta, result_distance, cases = eval_distance(Predict_Points, GT_Points) # RetinaNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ppoints' is not defined"
     ]
    }
   ],
   "source": [
    "def eval_distance(yhat,y):\n",
    "    result_delta = np.zeros_like(y).astype(np.float32)\n",
    "    result_distance = result_delta.copy()[...,0].astype(np.float32)\n",
    "    cases = list()\n",
    "    \n",
    "    # 테스트셋의 경우 이미지 전치리하기를 x,y pixel spacing을 0.15로 맞췄음! \n",
    "    dx = 0.15\n",
    "    dy = 0.15\n",
    "    # dx = 1\n",
    "    # dy = 1\n",
    "    \n",
    "    for idx_image in range(len(result_delta)):\n",
    "        case = 'A' if y[idx_image][6][0] < y[idx_image][7][0] else 'P' # A for anteria, P for posteria   바닥의 점을 기준으로 anteria posteria 구분, (x = 0, y = 0) 은 좌측 상단 \n",
    "        direction = 1 if case == 'A' else -1\n",
    "        cases.append(case)\n",
    "        for idx_lm in range(result_delta.shape[1]):\n",
    "            delta_x = (- y[idx_image][idx_lm][0] + yhat[idx_image][idx_lm][0])*direction\n",
    "            delta_y = - y[idx_image][idx_lm][1] + yhat[idx_image][idx_lm][1]\n",
    "            result_delta[idx_image][idx_lm][0] = (delta_x*dx).astype(np.float32)\n",
    "            result_delta[idx_image][idx_lm][1] = -(delta_y*dy).astype(np.float32)\n",
    "            result_distance[idx_image][idx_lm] = np.sqrt((dx*delta_x)**2+(dy*delta_y)**2)\n",
    "    \n",
    "    return result_delta, result_distance, cases\n",
    "    \n",
    "result_delta, result_distance, cases = eval_distance(ppoints, GT_Points) # Unet \n",
    "# result_delta, result_distance, cases = eval_distance(Predict_Points, GT_Points) # RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'])\n",
    "# tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "def compute_pairedT(df1,df2,absolute=False):\n",
    "    print('absolute',absolute)\n",
    "    df1 = df1.round(4)\n",
    "    df2 = df2.round(4)\n",
    "    \n",
    "    tstats = []\n",
    "    pvalues = []\n",
    "\n",
    "    for idx in range(0,3):\n",
    "        if absolute:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']),axis=0)\n",
    "        else:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'],axis=0)\n",
    "        tstats.append(tstat)\n",
    "        pvalues.append(pvalue)\n",
    "    df1_stack = []\n",
    "    df2_stack = []\n",
    "    for idx in range(0,3):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "    if absolute:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1_stack), np.abs(df2_stack),axis=0)\n",
    "    else:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(df1_stack, df2_stack,axis=0)\n",
    "    tstats.append(tstat)\n",
    "    pvalues.append(pvalue)    \n",
    "\n",
    "    for idx in range(3,8):\n",
    "        if absolute:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']),axis=0)\n",
    "        else:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'],axis=0)\n",
    "        tstats.append(tstat)\n",
    "        pvalues.append(pvalue)\n",
    "    df1_stack = []\n",
    "    df2_stack = []\n",
    "    for idx in range(3,8):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "    if absolute:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1_stack), np.abs(df2_stack),axis=0)\n",
    "    else:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(df1_stack, df2_stack,axis=0)\n",
    "    tstats.append(tstat)\n",
    "    pvalues.append(pvalue)\n",
    "    \n",
    "\n",
    "    for idx in range(8,12):\n",
    "        if absolute:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']),axis=0)\n",
    "        else:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'],axis=0)\n",
    "        tstats.append(tstat)\n",
    "        pvalues.append(pvalue)\n",
    "    for idx in range(20,25):\n",
    "        if absolute:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']),axis=0)\n",
    "        else:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'],axis=0)\n",
    "        tstats.append(tstat)\n",
    "        pvalues.append(pvalue)\n",
    "    df1_stack = []\n",
    "    df2_stack = []\n",
    "    for idx in range(8,12):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "    for idx in range(20,25):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "    if absolute:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1_stack), np.abs(df2_stack),axis=0)\n",
    "    else:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(df1_stack,df2_stack,axis=0)\n",
    "    \n",
    "    # print('df1_stack')\n",
    "    # for idx in range(len(df1_stack)):\n",
    "    #     print(np.abs(df1_stack[idx]))\n",
    "    # print('\\n df2_stack')\n",
    "    # for idx in range(len(df2_stack)):\n",
    "    #     print(np.abs(df2_stack[idx]))\n",
    "    tstats.append(tstat)\n",
    "    pvalues.append(pvalue)\n",
    "    \n",
    "\n",
    "    for idx in range(12,20):\n",
    "        if absolute:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1[f'{idx}']), np.abs(df2[f'{idx}']),axis=0)\n",
    "        else:\n",
    "            tstat,pvalue = scipy.stats.ttest_rel(df1[f'{idx}'], df2[f'{idx}'],axis=0)\n",
    "        tstats.append(tstat)\n",
    "        pvalues.append(pvalue)\n",
    "    df1_stack = []\n",
    "    df2_stack = []\n",
    "    for idx in range(12,20):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "    if absolute:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1_stack), np.abs(df2_stack),axis=0)\n",
    "    else:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(df1_stack,df2_stack,axis=0)\n",
    "    tstats.append(tstat)\n",
    "    pvalues.append(pvalue)\n",
    "    \n",
    "    df1_stack = []\n",
    "    df2_stack = []\n",
    "    for idx in range(0,25):\n",
    "        df1_stack.extend(df1[f'{idx}'])\n",
    "        df2_stack.extend(df2[f'{idx}'])\n",
    "        \n",
    "    if absolute:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(np.abs(df1_stack), np.abs(df2_stack),axis=0)\n",
    "    else:\n",
    "        tstat,pvalue = scipy.stats.ttest_rel(df1_stack,df2_stack,axis=0)\n",
    "        \n",
    "    # print('df1_stack')\n",
    "    # for idx in range(len(df1_stack)):\n",
    "    #     print(np.abs(df1_stack[idx]))\n",
    "    # print('\\n df2_stack')\n",
    "    # for idx in range(len(df2_stack)):\n",
    "    #     print(np.abs(df2_stack[idx]))\n",
    "    \n",
    "    tstats.append(tstat)\n",
    "    pvalues.append(pvalue)\n",
    "    \n",
    "    df = pd.DataFrame([tstats,pvalues],['tstats','pvalues'])\n",
    "    df = df.T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Unet_ROI1024_distance.csv 150 Unet_ROI1024_distance.csv 150\n",
      "absolute True\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "\n",
      "\n",
      "Unet_ROI1024_distance.csv 150 UnetwoSCSE_ROI1024_distance.csv 150\n",
      "absolute True\n",
      "0.001\n",
      "0.000\n",
      "0.072\n",
      "0.000\n",
      "0.000\n",
      "0.467\n",
      "0.000\n",
      "0.000\n",
      "0.028\n",
      "0.000\n",
      "0.711\n",
      "0.005\n",
      "0.007\n",
      "0.003\n",
      "0.104\n",
      "0.014\n",
      "0.353\n",
      "0.000\n",
      "0.100\n",
      "0.000\n",
      "0.002\n",
      "0.000\n",
      "0.000\n",
      "0.222\n",
      "0.000\n",
      "0.152\n",
      "0.919\n",
      "0.005\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "Unet_ROI1024_distance.csv 150 Kim1024_distance.csv 150\n",
      "absolute True\n",
      "0.096\n",
      "0.851\n",
      "0.540\n",
      "0.804\n",
      "0.236\n",
      "0.386\n",
      "0.004\n",
      "0.078\n",
      "0.797\n",
      "0.655\n",
      "0.001\n",
      "0.007\n",
      "0.776\n",
      "0.000\n",
      "0.000\n",
      "0.147\n",
      "0.000\n",
      "0.000\n",
      "0.009\n",
      "0.000\n",
      "0.063\n",
      "0.357\n",
      "0.001\n",
      "0.094\n",
      "0.000\n",
      "0.226\n",
      "0.000\n",
      "0.248\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "Unet_ROI1024_distance.csv 150 FPAM_distance.csv 150\n",
      "absolute True\n",
      "0.002\n",
      "0.000\n",
      "0.459\n",
      "0.443\n",
      "0.203\n",
      "0.911\n",
      "0.572\n",
      "0.000\n",
      "0.840\n",
      "0.037\n",
      "0.604\n",
      "0.023\n",
      "0.025\n",
      "0.198\n",
      "0.000\n",
      "0.099\n",
      "0.740\n",
      "0.027\n",
      "0.033\n",
      "0.018\n",
      "0.429\n",
      "0.221\n",
      "0.787\n",
      "0.428\n",
      "0.062\n",
      "0.002\n",
      "0.124\n",
      "0.599\n",
      "0.096\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "coord = 'x'\n",
    "coord = 'y'\n",
    "coord = 'distance'\n",
    "absolute = True\n",
    "\n",
    "path1 = f'Unet_ROI512_{coord}.csv'\n",
    "path1 = f'Unet_ROI1024_{coord}.csv'\n",
    "\n",
    "paths2 = [f'Unet_ROI1024_{coord}.csv',\n",
    "          f'UnetwoSCSE_ROI1024_{coord}.csv',\n",
    "          f'Kim1024_{coord}.csv',\n",
    "          f'FPAM_{coord}.csv',]\n",
    "\n",
    "for path2 in paths2:\n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(path1,len(df1),path2,len(df2))\n",
    "    df = compute_pairedT(df1,df2,absolute=absolute)\n",
    "    for idx in range(len(df['pvalues'])):\n",
    "        print('{:.3f}'.format(df['pvalues'][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
